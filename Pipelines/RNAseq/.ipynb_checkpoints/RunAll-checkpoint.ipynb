{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Pipeline Code| \n",
    "|---- | \n",
    "| [Calcualate unprocessed](./calculate_unprocessed.ipynb)|\n",
    "| [merge RNAseq data into transcripts](./Pipelines/RNAseq/merge/mergeKallistoOutputIntoTranscript.ipynb)|\n",
    "| [reduce transcripts count to gene count using sum ](./Pipelines/RNAseq/merge/reduceToGeneLevel.ipynb)|\n",
    "|[merge data into single numpy mmap matrix ](./Pipelines/RNAseq/merge/mergeGeneMatrix.ipynb)\n",
    "| [upload expression data to AWS (On this step now)](./Pipelines/RNAseq/merge/upload_AWS.ipynb)|\n",
    "\n",
    "|Auxilary Code|\n",
    "|---- | \n",
    "| [file count](./Pipelines/RNAseq/merge/fileCount.ipynb)|\n",
    "| [merge Kalististo mapping stats](./Pipelines/RNAseq/merge/mergeKalistoMappingStats.ipynb)|\n",
    "\n",
    "\n",
    "Status\n",
    "\n",
    "* [Generating refs](http://localhost:6001/notebooks/Project/METAMAP/notebook/RapMapTest/RNAseq/generateReferences.ipynb)\n",
    "* Running all the new RNAseq data now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your job-array 444392.1-488705:1 (\"all_seq.sh\") has been submitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook calculate_unprocessed.ipynb to notebook\n",
      "[NbConvertApp] Executing notebook with kernel: python3\n",
      "Permission denied, please try again.\r\n",
      "Permission denied, please try again.\r\n",
      "Permission denied (publickey,password).\r\n",
      "Permission denied, please try again.\r\n",
      "Permission denied, please try again.\r\n",
      "Permission denied (publickey,password).\r\n",
      "Permission denied, please try again.\r\n",
      "Permission denied, please try again.\r\n",
      "Permission denied (publickey,password).\r\n",
      "Permission denied, please try again.\r\n",
      "Permission denied, please try again.\r\n",
      "Permission denied (publickey,password).\r\n",
      "[NbConvertApp] ERROR | Error while converting 'calculate_unprocessed.ipynb'\n",
      "Traceback (most recent call last):\n",
      "  File \"/cellar/users/btsui/anaconda3/lib/python3.6/site-packages/nbconvert/nbconvertapp.py\", line 393, in export_single_notebook\n",
      "    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)\n",
      "  File \"/cellar/users/btsui/anaconda3/lib/python3.6/site-packages/nbconvert/exporters/exporter.py\", line 174, in from_filename\n",
      "    return self.from_file(f, resources=resources, **kw)\n",
      "  File \"/cellar/users/btsui/anaconda3/lib/python3.6/site-packages/nbconvert/exporters/exporter.py\", line 192, in from_file\n",
      "    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)\n",
      "  File \"/cellar/users/btsui/anaconda3/lib/python3.6/site-packages/nbconvert/exporters/notebook.py\", line 31, in from_notebook_node\n",
      "    nb_copy, resources = super(NotebookExporter, self).from_notebook_node(nb, resources, **kw)\n",
      "  File \"/cellar/users/btsui/anaconda3/lib/python3.6/site-packages/nbconvert/exporters/exporter.py\", line 134, in from_notebook_node\n",
      "    nb_copy, resources = self._preprocess(nb_copy, resources)\n",
      "  File \"/cellar/users/btsui/anaconda3/lib/python3.6/site-packages/nbconvert/exporters/exporter.py\", line 311, in _preprocess\n",
      "    nbc, resc = preprocessor(nbc, resc)\n",
      "  File \"/cellar/users/btsui/anaconda3/lib/python3.6/site-packages/nbconvert/preprocessors/base.py\", line 47, in __call__\n",
      "    return self.preprocess(nb, resources)\n",
      "  File \"/cellar/users/btsui/anaconda3/lib/python3.6/site-packages/nbconvert/preprocessors/execute.py\", line 262, in preprocess\n",
      "    nb, resources = super(ExecutePreprocessor, self).preprocess(nb, resources)\n",
      "  File \"/cellar/users/btsui/anaconda3/lib/python3.6/site-packages/nbconvert/preprocessors/base.py\", line 69, in preprocess\n",
      "    nb.cells[index], resources = self.preprocess_cell(cell, resources, index)\n",
      "  File \"/cellar/users/btsui/anaconda3/lib/python3.6/site-packages/nbconvert/preprocessors/execute.py\", line 286, in preprocess_cell\n",
      "    raise CellExecutionError.from_cell_and_msg(cell, out)\n",
      "nbconvert.preprocessors.execute.CellExecutionError: An error occurred while executing the following cell:\n",
      "------------------\n",
      "hitDf=targetMetaDF.loc[['SRR998545','SRR998530','SRR949118']]\n",
      "------------------\n",
      "\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-36-80bc64521e31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhitDf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargetMetaDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SRR998545'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SRR998530'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SRR949118'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n",
      "\u001b[1;32m   1899\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot index with multidimensional key'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1901\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1903\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n",
      "\u001b[1;32m   1141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1142\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1143\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1145\u001b[0m                 \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n",
      "\u001b[1;32m   1204\u001b[0m                 raise KeyError(\n",
      "\u001b[1;32m   1205\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n",
      "\u001b[0;32m-> 1206\u001b[0;31m                         key=key, axis=self.obj._get_axis_name(axis)))\n",
      "\u001b[0m\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1208\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [['SRR998545', 'SRR998530', 'SRR949118']] are in the [index]\"\n",
      "KeyError: \"None of [['SRR998545', 'SRR998530', 'SRR949118']] are in the [index]\"\n",
      "\n",
      "\n",
      "real\t2m38.767s\n",
      "user\t2m1.596s\n",
      "sys\t0m59.428s\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "time jupyter nbconvert --execute --to notebook --ExecutePreprocessor.timeout=-1 --inplace calculate_unprocessed.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#run at 'Project/METAMAP/notebook/RapMapTest/Pipelines'\r\n",
      "\r\n",
      "import os,sys\r\n",
      "sys.path+=['/cellar/users/btsui/Project/METAMAP/notebook/RapMapTest/Pipelines/RNAseq/']\r\n",
      "import pandas as pd\r\n",
      "import subprocess\r\n",
      "from multiprocessing import Process\r\n",
      "import param\r\n",
      "TEST=False\r\n",
      "nThread=3\r\n",
      "\r\n",
      "#specieToRefDict={'Homo_sapiens':'Homo_sapiens.GRCh38.dna_rm.toplevel.fa'}\r\n",
      "def startChildren(cmd):\r\n",
      "    def f():\r\n",
      "        os.system(cmd) \r\n",
      "        #p.close()\r\n",
      "    p = Process(target=f)\r\n",
      "    p.start()\r\n",
      "    return p\r\n",
      "\r\n",
      "if TEST:\r\n",
      "    srrRun='SRR2084809'\r\n",
      "    specie='Homo_sapiens'\r\n",
      "    downloadSpeed='2000000'\r\n",
      "else:\r\n",
      "    srrRun=sys.argv[1]\r\n",
      "    specie=sys.argv[2]\r\n",
      "    downloadSpeed='200000'\r\n",
      "\r\n",
      "print srrRun,specie\r\n",
      "#baseGenomesDir='/cellar/users/btsui/Data/BOWTIE_GENOME_SNP_INDEX/'\r\n",
      "baseGenomesDir='/cellar/users/btsui/Data/BOWTIE_GENOME_SNP_INDEX/'\r\n",
      "snpBed='/cellar/users/btsui/Data/dbsnp/snp_beds/'+specie+'.bed'\r\n",
      "fa_dir='/cellar/users/btsui/Data/ensembl/snp_masked/'+specie+'.microbe.fa'\r\n",
      "\r\n",
      "log_out_dir=param.log_out_dir#'/cellar/users/btsui/Data/SRA/all_seq/log/'\r\n",
      "count_out_dir=param.count_out_dir#'/cellar/users/btsui/Data/SRA/all_seq/chip/'\r\n",
      "genomeDir=baseGenomesDir+specie+'/'\r\n",
      "tmp_dir=\"/tmp/SRA_DATA/\"\r\n",
      "\r\n",
      "#count_script_dir='/cellar/users/btsui/Project/METAMAP/notebook/RapMapTest/Chip-seq/count'\r\n",
      "SRA_FASTQ_TOOL_DIR=\"/cellar/users/btsui/Program/SRA_TOOL_KIT/sratoolkit.2.4.2-ubuntu64/bin/fastq-dump.2.4.2\"\r\n",
      "myoption=r'\"/cellar/users/btsui/.aspera/connect/bin/ascp|/cellar/users/btsui/.aspera/connect/etc/asperaweb_id_dsa.openssh\"'\r\n",
      "bam_read_count_dir='/cellar/users/btsui/Program/bam_read_count/bam-readcount-master/bin/bam-readcount'\r\n",
      "\r\n",
      "trim_galore_Dir='/cellar/users/btsui/Program/TRIMAGLORE//trim_galore'\r\n",
      "base_sra_dir='/tmp/btsui/METH/sra/'\r\n",
      "\r\n",
      "##make temperoary directory\r\n",
      "job_tmp_dir=tmp_dir+srrRun+\"/\"\r\n",
      "#if not TEST:\r\n",
      "#    subprocess.call([\"rm\", \"-rf\",job_tmp_dir])#remove the directory before running STAR\r\n",
      "subprocess.call([\"mkdir\", \"-p\",job_tmp_dir]) #tmp dir for processing\r\n",
      "\r\n",
      "os.chdir(job_tmp_dir)\r\n",
      "##download sra file\r\n",
      "#downloadCommand=['prefetch','-t','ascp','--ascp-path',myoption,' --ascp-options \"-l {max_traffic}\" '.format(max_traffic=downloadSpeed),srrRun]\r\n",
      "downloadCommand=['prefetch',srrRun]\r\n",
      "os.system(' '.join(downloadCommand))\r\n",
      "\r\n",
      "##identify adaptor contents using first 10000 reads\r\n",
      "\"\"\"\r\n",
      "base_sra_dir+srrRun+'.sra'\r\n",
      "\"\"\"\r\n",
      "\r\n",
      "\r\n",
      "myCmd='{sra_dump_dir} --stdout {sra_file_dir} |head -n 10000 > head.fq'.format(sra_dump_dir=SRA_FASTQ_TOOL_DIR,                                    sra_file_dir=base_sra_dir+srrRun+'.sra',trim_galore_Dir=trim_galore_Dir)\r\n",
      "os.system(myCmd) \r\n",
      "os.system(trim_galore_Dir+' '+'head.fq')\r\n",
      "##identify adaptor contents\r\n",
      "fq_trimming_report_S=pd.Series.from_csv('head.fq_trimming_report.txt',index_col=None,sep='\\t\\t\\t\\t\\\\t\\t\\tt')\r\n",
      "adapter_sequence=fq_trimming_report_S.str.extract(\"Adapter sequence: '(\\w+)'\",expand=False).dropna().iloc[0]\r\n",
      "##set up pipe for counting the data\r\n",
      "##remove pipes if they exist \r\n",
      "os.system('rm {srrRun}_bowtie_in.fq  {srrRun}_bowtie_out.fq'.format(srrRun=srrRun))#{srrRun}_bowtie_out, file_sorted\r\n",
      "os.system('mkfifo {srrRun}_bowtie_in.fq   {srrRun}_bowtie_out.fq'.format(srrRun=srrRun))#{srrRun}_bowtie_out,file_sorted\r\n",
      "\r\n",
      "cmd_0='samtools view -bS {srrRun}_bowtie_out | samtools sort -  > file_sorted'.format(srrRun=srrRun)\r\n",
      "##########\r\n",
      "####\r\n",
      "#### genomebuild\r\n",
      "####\r\n",
      "##########\r\n",
      "kalisto_transcriptome_dir='/cellar/users/btsui/Data/kalisto_ref/'+specie\r\n",
      "#take in and sort it \r\n",
      "\"\"\"\r\n",
      "sailfish quant -i sfindex -l U -r <(gunzip -c reads.fq.gz) -o reads_quant\r\n",
      "\r\n",
      "\"\"\"\r\n",
      "#kallisto quant -i transcripts.idx -o output -b 100 reads_1.fastq.gz reads_2.fastq.gz\r\n",
      "\r\n",
      "#### parameter from : https://pachterlab.github.io/kallisto/starting\r\n",
      "cmd_sailfish=\" \".join(['/cellar/users/btsui/Program/kallisto',\r\n",
      "                       'quant --single -l 180 -s 20 -i' ,kalisto_transcriptome_dir,\r\n",
      "                       '-o','read_quant',\r\n",
      "                       srrRun+\"_bowtie_in.fq\",\r\n",
      "                      ])\r\n",
      "#print os.system(cmd_sailfish)\r\n",
      " #           os.system(\" \".join([SAILFISH_DIR,SAILFISH_TRANSCRIPTOME_DIR,job_tmp_dir,job_tmp_dir+id+\"_1.fastq \"]))\r\n",
      "    \r\n",
      "RUN_FULL=True\r\n",
      "if TEST and (RUN_FULL != True):\r\n",
      "    cmd_2_fmt='{sra_dump_dir} --stdout {sra_file_dir} | head -n 2000000 |cutadapt -a {adapter_sequence_1} -m 30- > {srrRun}_bowtie_in.fq'\r\n",
      "else:\r\n",
      "    cmd_2_fmt='{sra_dump_dir} --stdout {sra_file_dir} |cutadapt  -m 30 -a {adapter_sequence_1} - > {srrRun}_bowtie_in.fq'\r\n",
      "    \r\n",
      "cmd_2=cmd_2_fmt.format(\r\n",
      " sra_file_dir=base_sra_dir+srrRun+'.sra',srrRun=srrRun,adapter_sequence_1=adapter_sequence,sra_dump_dir=SRA_FASTQ_TOOL_DIR)\r\n",
      "###execute code\r\n",
      "#cmd1: botwie, cmd0: samtools, cmd_2: trimming\r\n",
      "my_p_l=[ startChildren(cmd_2)]\r\n",
      "#os.system(cmd_2)#\r\n",
      "os.system(cmd_sailfish)\r\n",
      "\"\"\"\r\n",
      "pd.read_csv('./read_quant/quant.sf',sep='\\t')['NumReads'].sum()\r\n",
      "\"\"\"\r\n",
      "\"\"\"\r\n",
      "###index and identify the regions of interest\r\n",
      "os.system('samtools index file_sorted')##ADDED\r\n",
      "os.system('samtools idxstats file_sorted |gzip> per_fa_record_stat.txt.gz')##ADDED\r\n",
      "\r\n",
      "cmd_5=bam_read_count_dir+' -l '+snpBed+' -f '+fa_dir+' file_sorted |gzip > snp.txt.gz'\r\n",
      "os.system(cmd_5)\r\n",
      "\r\n",
      "os.system('echo \">>>>bowtie2 log\" >log.txt')\r\n",
      "os.system('tail -n 10 bowtie_log.txt >>log.txt')\r\n",
      "os.system('echo \">>>>head.fq_trimming_report.txt\">>log.txt')\r\n",
      "os.system('cat head.fq_trimming_report.txt >> log.txt')\r\n",
      "os.system('cp log.txt {log_out_dir}/{srrRun}.log'.format(log_out_dir=log_out_dir,\r\n",
      "                                                        srrRun=srrRun))\r\n",
      "\"\"\"\r\n",
      "### copy out the results\r\n",
      "os.system('gzip ./read_quant/abundance.tsv')\r\n",
      "os.system('gzip ./read_quant/run_info.json')\r\n",
      "\r\n",
      "os.system('cp ./read_quant/abundance.tsv.gz {count_out_dir}/{srrRun}.abundance.tsv.gz'.format(\r\n",
      "    count_out_dir=count_out_dir,srrRun=srrRun))\r\n",
      "os.system('cp ./read_quant/run_info.json.gz {count_out_dir}/{srrRun}.run_info.json.gz'.format(\r\n",
      "    count_out_dir=count_out_dir,srrRun=srrRun))\r\n",
      "#os.system('cp per_fa_record_stat.txt.gz {count_out_dir}/{srrRun}_per_fa_record_stat.txt.gz'.format(\r\n",
      "#    count_out_dir=count_out_dir,srrRun=srrRun))##ADDED\r\n",
      "\r\n",
      "os.system('rm -r '+job_tmp_dir)\r\n",
      "os.system('rm '+base_sra_dir+srrRun+'.sra')\r\n",
      "#os._exit(0)\r\n",
      "\r\n",
      "\"\"\"\r\n",
      "#old code\r\n",
      "print cmd_0\r\n",
      "print cmd_1\r\n",
      "print cmd_2\r\n",
      "#cmd_2, cut adapt, to bowtie, \r\n",
      "my_p_l=[startChildren(cmd_0),startChildren(cmd_1),startChildren(cmd_2)]\r\n",
      "os.system(cmd_4)\r\n",
      "tmp_cmd='gzip -c out.bg >  {count_out_dir}/{srrRun}.bg.gz'.format(count_out_dir=count_out_dir,srrRun=srrRun)\r\n",
      "\r\n",
      "os.system(tmp_cmd)\r\n",
      "\r\n",
      "os.system('echo \">>>>bowtie2 log\" >log.txt')\r\n",
      "os.system('tail -n 10 bowtie_log.txt >>log.txt')\r\n",
      "os.system('echo \">>>>head.fq_trimming_report.txt\">>log.txt')\r\n",
      "os.system('cat head.fq_trimming_report.txt >> log.txt')\r\n",
      "os.system('cp log.txt {log_out_dir}/{srrRun}.log'.format(log_out_dir=log_out_dir,\r\n",
      "                                                        srrRun=srrRun))\r\n",
      "\r\n",
      "\r\n",
      "#os.system('gzip -c out.bg > {count_out_dir}/{srrRun}.bg.gz'.format(\r\n",
      "#    count_out_dir=count_out_dir,srrRun=srrRun))\r\n",
      "os.system('rm -r '+job_tmp_dir)\r\n",
      "os.system('rm '+base_sra_dir+srrRun+'.sra')\r\n",
      "os._exit(0)\r\n",
      "\"\"\"\r\n"
     ]
    }
   ],
   "source": [
    "!cat single_rna.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd merge\n",
    "time jupyter nbconvert --execute --to notebook --ExecutePreprocessor.timeout=-1 --inplace mergeKallistoOutputIntoTranscript.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd merge\n",
    "time jupyter nbconvert --execute --to notebook --ExecutePreprocessor.timeout=-1 --inplace reduceToGeneLevel.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd merge\n",
    "time jupyter nbconvert --execute --to notebook --ExecutePreprocessor.timeout=-1 --inplace mergeGeneMatrix.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat ./merge/mergeGeneMatrix.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd mergeGeneMatrix.ipynb\n",
    "time jupyter nbconvert --execute --to notebook --ExecutePreprocessor.timeout=-1 --inplace upload_AWS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd merge/mergeKalistoMappingStats.ipynb\n",
    "time jupyter nbconvert --execute --to notebook --ExecutePreprocessor.timeout=-1 --inplace upload_AWS.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
